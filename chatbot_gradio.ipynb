{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.2.0 (SDL 2.0.22, Python 3.11.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import gradio as gr\n",
    "import os\n",
    "from gtts import gTTS\n",
    "import subprocess\n",
    "import tempfile\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from pygame import mixer\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "messages=[\n",
    "  {\"role\":\"system\",\"content\":\"You are a helpful therapist\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def say(text,filename=None):\n",
    "  with tempfile.NamedTemporaryFile(delete=True) as temp:\n",
    "    tts = gTTS(text=text,lang='en',slow=False)\n",
    "    if filename is None:\n",
    "      filename = f'{temp.name}.mp3'\n",
    "    print(os.path.abspath(filename))\n",
    "    tts.save(filename)\n",
    "    mixer.init()\n",
    "    mixer.music.load(filename)\n",
    "    mixer.music.play()\n",
    "    while mixer.music.get_busy():\n",
    "      continue\n",
    "    mixer.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def transcribe(audio):\n",
    "  global messages\n",
    "\n",
    "  audio_file = open(audio, 'rb')\n",
    "  print(audio_file)\n",
    "  transcript = openai.Audio.transcribe('whisper-1',audio_file)\n",
    "  print(transcript['text'])\n",
    "\n",
    "  messages.append({\"role\":\"user\",\"content\":transcript['text']})\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "  )\n",
    "\n",
    "  system_message = response['choices'][0]['message']['content']\n",
    "  # say(system_message,\"system.mp3\")\n",
    "  subprocess.call(['say', system_message, '-o', 'system.aiff'])\n",
    "  subprocess.call(['ffmpeg','-y','-i', 'system.aiff', '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', 'system.wav'])\n",
    "\n",
    "  messages.append({\"role\":\"assistant\",\"content\":system_message})\n",
    "\n",
    "  chat_transcript = \"\"\n",
    "  for msg in messages:\n",
    "    if msg['role'] != 'system':\n",
    "      chat_transcript += f'{msg[\"role\"]}: {msg[\"content\"]}\\n\\n'\n",
    "\n",
    "  return chat_transcript\n",
    "\n",
    "ui = gr.Interface(\n",
    "  fn=transcribe,\n",
    "  inputs=gr.Audio(source=\"microphone\", type=\"filepath\"),\n",
    "  outputs=[gr.Audio('system.wav'),\"text\"],\n",
    ")\n",
    "\n",
    "ui.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BufferedReader name='/private/var/folders/vk/rlpkh5414m95phky_z9_d7pm0000gn/T/audio54da8659c898165b37ccd49761b4e692889443e6-0-100.wav'>\n",
      "Thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with Apple clang version 14.0.0 (clang-1400.0.29.202)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/5.1.2_5 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-neon\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : mono\n",
      "Input #0, aiff, from 'system.aiff':\n",
      "  Duration: 00:00:02.33, start: 0.000000, bitrate: 366 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16be (twos / 0x736F7774), 22050 Hz, mono, s16, 352 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16be (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'system.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf59.27.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 pcm_s16le\n",
      "size=      73kB time=00:00:02.33 bitrate= 256.3kbits/s speed=1.63e+03x    \n",
      "video:0kB audio:73kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.104406%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ui = gr.Interface(\n",
    "  fn=transcribe,\n",
    "  inputs=gr.Audio(source=\"microphone\", type=\"filepath\",streaming=True),\n",
    "  # outputs=[gr.Audio('system1.wav'),\"text\"],\n",
    "  outputs=[\"html\"]\n",
    ")\n",
    "\n",
    "ui.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
